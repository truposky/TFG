\section{Localización de los robots}\label{ch:localizacionRobots}
Una vez que se tienen calibrados los robots para que estimen la velocidad y puedan hacer un control de la velocidad de cada rueda y además, se tiene configurada la navegación para comandar al robot, se diseña y programa un sistema para posicionar al robot en coordenadas mundo correspondientes al Robotario.\\

Para localizar los distintos robots involucrados en el Robotario se usan cámaras. Se tiene una cámara cenital y cada robot dispone de una cámara conectada a una raspberryPi, que son las cámaras mencionadas en el capítulo ~\ref{ch:HardwareYsoftware}. Para obtener información del entorno con las cámaras se usa la librería OpenCV. La librería tiene múltiples aplicaciones para el reconocimiento del entorno. En particular, para determinar la posición y orientación de los robots se van a usar unas figuras denominadas Markers que constan de un fondo negro, y en blanco tienen un identificador, la información que se puede almacenar en el Marker consta de 16 bits. El borde es negro lo que permite su rápida localización en el entorno, además la forma del Marker es cuadrada, con todos los lados iguales. Cada esquina del Marker se identifica de manera única y se guarda su localización en pixeles, esto permite obtener la orientación del Marker en el mundo observado por la cámara, se detalla el proceso más adelante. Para identificar y crear los diferentes Marker se debe usar un diccionario prefijado por la librería ArUcO que pertenece a OpenCV como se mencionó en la sección ~\ref{ch:openCV}. La librería tiene 16 diccionarios y cada uno codifica el Marker de manera diferente. Las principales características del diccionario son el numero de Markers a usar y sus dimensiones.\\

	\begin{figure}[!h]
	\centering
	\includegraphics[width=0.5\linewidth]{Localizacion/board}
	\caption{Markers para calibración}
	\label{fig:eMarkerBoard}
\end{figure}
\subsection{Calibración de cámaras}
Para poder localizar los robots, primero se deben calibrar las cámaras para convertir los pixeles de la imagen de la cámara en unidades físicas. Existen diversas maneras de hacerlo. Se ha seguido la proporcionada por ArUcO, la cual consiste en disponer de una tabla de Markers, como la mostrada en la figura~\ref{fig:eMarkerBoard} donde se debe medir las dimensiones físicas de los Markers, que deben ser todos del mismo tamaño y cada uno con un identificador diferente. También se debe medir la distancia que  los separa, que también debe ser igual para todos. Con el programa proporcionado por ArUco, se pasan los parámetros físicos de los Markers a una función de la librería de ArUcO y se obtienen los coeficientes de distorsión de la cámara y  los parámetros de la longitud focal y los centros ópticos, correspondientes con los ejes x e y del mundo observado con la cámara. Con estos últimos se crea una matriz única para cada cámara.
\begin{equation}
\begin{bmatrix}
fx & 0 & cx\\
0 & fy & cy\\
0 & 0 & 1
\end{bmatrix}
\end{equation} 

La matriz y los coeficientes de distorsión se utilizan para localizar en unidades físicas (metros) donde se encuentran los diferentes Markers identificados por la cámara. También se puede conocer su orientación respecto a los ejes de la cámara. Para ello se emplean las esquinas de cada Marker, siendo cada una identificada y guardada. Se puede identificar la orientación calculando el centroide del cuadrado y el ángulo respecto a una esquina de referencia, está es siempre la superior izquierda del Marker. Observando la figura \ref{fig:eMarkerBoard} las esquinas se cuentan en el sentido de las agujas del reloj empezando por la esquina superior izquierda y acabando por la inferior izquierda.\\

\subsection{Identificación y localización}\label{ch:localizacionMatriz}
La cámara tiene sus  propios ejes, siendo el centro del foco el origen de coordenadas. La cámara tiene el eje Z apuntado fuera de su foco, el eje X apunta de izquierda a derecha de la imagen y el eje Y apunta de arriba a abajo de la imagen. Es importante tener en cuenta la orientación de los ejes de la cámara para poder localizar los robots en el mundo.
Para localizar un Marker y estimar su posición en coordenadas XYZ en metros, OpenCV tiene una serie de funciones que permiten hacerlo. Primero se debe identificar donde se encuentra el Marker en la imagen que proporciona la cámara. Esto se hace con la función $ cv::aruco::detectMarkers(image, dictionary, corners, ids)$, esta función te devuelve un array de vectores con la localización de las esquinas de cada Marker en pixeles y con el identificador del Marker localizado, los parámetros que se tienen que pasar son, el frame o captura de la imagen y el diccionario que se está usando.\\
El siguiente paso es estimar la posición. Para ello se necesitan los coeficientes de distorsión, la matriz de la cámara y la dimensión del Marker en metros. Siendo estos cuadrados basta con conocer un lado. La función que permite conocer la posición y orientación es la siguiente:
\begin{lstlisting} 
cv::aruco::estimatePoseSingleMarkers(corners, marker_length_m,camera_matrix, dist_coeffs, rvecs, tvecs); 
\end{lstlisting}
A esta función se le deben pasar los parámetros mencionados y te devuelve un vector de traslación $tvecs$ y un vector de rotación $rvecs$ con estos vectores se puede conocer la posición de cada Marker y su respectiva orientación. Permite por tanto construir un sistema de referencia en coordenadas locales del robot, con origen en el centro del Marker\\

En la figura~\ref{fig:poseEstimation} se puede ver como se localiza el Marker y sus ejes en su sitema de referenecia y en la figura~\ref{fig:ejescamara} se observa los ejes de la cámara, siendo  para ambos, el verde el eje X el rojo el eje Y y el azul el eje Z, 

Con el vector de rotación no bastaría para conocer la orientación, es preciso transformarlo en una matriz de rotación y esto se consigue con el algoritmo de Rodrigues\cite{rodrigues}.
\begin{figure}[h]
	
	\begin{subfigure}[b]{0.5\linewidth}
		\centering
		\includegraphics[width=0.9\linewidth]{PoseEstimation}
		\caption{Localizacion de Marker}
		\label{fig:poseEstimation}
	\end{subfigure}
	\quad
	\begin{subfigure}[b]{0.52\linewidth}
		\centering
		\includegraphics[width=0.5\linewidth]{ejesCamara}
		\caption{Ejes de la cámara}
		\label{fig:ejescamara}
	\end{subfigure}
	\caption{Ejes de coordenadas}
	\label{fig:EjesCoordenadas}
\end{figure}
En la figura~\ref{fig:EjesCoordenadas} se aprecia como la cámara tiene su sistema de coordenadas y el robot tiene el suyo, por ello es necesario el vector de rotación y el vector de traslación, que permite posteriormente dar instrucciones a los robots para moverse en el Robotario o localizarse unos a otros.
 Para obtener la orientación se emplea la matriz de rotación calculada a partir del vector de rotación proporcionado por la función descrita anteriormente. Con esta matriz se puede calcular el heading, que se corresponde con los grados girados respecto al eje Z de la cámara. La matriz de rotación es la matriz resultante de haber realizado las rotaciones respecto al eje x, y, z, para trasladar el sistema de referencia de la cámara al sistema de referencia del robot. Las matrices de rotación respecto a los ejes son:
\begin{equation}
Rx(u)=
\begin{bmatrix}
1 & 0 & 0\\
0 & cos(u) & -sin(u)\\
0 & sin(u) & cos(u)
\end{bmatrix}    
\end{equation}

\begin{equation}
Ry(v)=
\begin{bmatrix}
cos(v) & 0 & sin(v)\\
0 & 1 & 0\\
-sin(v) & 0 & cos(v)
\end{bmatrix}  
\end{equation}


\begin{equation}
Rz(w)=
\begin{bmatrix}
cos(w) & -sin(w) & 0\\
sin(w) & cos(w) & 0\\
0 & 0 & 1
\end{bmatrix}  
\end{equation}

Como resultado la multiplicación de las matrices da la matriz de rotación.

$R=R_{z}(w)R_{y}(v)R_{x}(u)=$
\begin{equation}
\begin{pmatrix}
cos(w)cos(v) & sin(u)sin(v)cos(w)-cos(u)sin(w) & cos(u)sin(v)cos(w)+sin(u)sin(w)\\
cos(v)sin(w) & sin(u)sin(v)sin(w)+ cos(u)cos(w) & cos(u)sin(v)sin(w)-sin(u)cos(w)\\
-sin(v) & sin(u)cos(v) & cos(u)cos(v)
\end{pmatrix}
\end{equation}

De la matriz de rotación se puede despejar el ángulo de rotación respecto al eje Z, a partir de los elementos de la matriz $R_{11}$ y $R_{21}$, se dividen ambos términos y se despeja el ángulo $w$ y de esta manera se obtiene el heading.
\begin{equation}
\frac{R_{21}}{R_{11}}=\tan(w)
\end{equation}
Con este parámetro ya se obtiene la orientación del robot respecto al eje Z del sistema de referencia de la cámara.

\subsection{Ruido en la estimación de posición}\label{ch:RuidoPosicion}
Se ha detectado que en la localización existe una variación en la posición. Las coordenadas devueltas por el programa oscilan incluso cuando el objeto está parado. En la figura~\ref{fig:Ruidolocalizacion} se tiene el ruido que se produce al localizar un Marker. La oscilación en la posición es de 2 cm, teniendo en cuenta que los Markers que se van a usar tienen unas dimensiones de 8 x 8 cm, el error no es significativo para la localización.

\begin{figure}[h!]
	\begin{subfigure}[b]{0.55\linewidth}
	\centering
	\includegraphics[width=0.7\linewidth]{Localizacion/oscilacionX}
	\caption{Oscilación respecto al eje x}
	\label{fig:oscilacionx}
\end{subfigure}
	\begin{subfigure}[b]{0.55\linewidth}
	\centering
	\includegraphics[width=0.7\linewidth]{Localizacion/oscilacionY}
	\caption{oscilación respecto al eje y}
	\label{fig:oscilaciony}
\end{subfigure}
\caption{Rudio en la localización}
\label{fig:Ruidolocalizacion}
\end{figure}

